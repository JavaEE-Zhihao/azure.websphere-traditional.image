# This is a basic workflow to help you get started with Actions

name: twas-base-cis CICD

# Controls when the action will run. 
on:
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
  # Allows you to run this workflow using GitHub APIs
  # PERSONAL_ACCESS_TOKEN=<GITHUB_PERSONAL_ACCESS_TOKEN>
  # REPO_NAME=WASdev/azure.websphere-traditional.image
  # curl --verbose -XPOST -u "WASdev:${PERSONAL_ACCESS_TOKEN}" -H "Accept: application/vnd.github.everest-preview+json" -H "Content-Type: application/json" https://api.github.com/repos/${REPO_NAME}/actions/workflows/twas-base-cisBuild.yml/dispatches --data '{"ref": "main"}'
  repository_dispatch:
    types: [integration-test-twasbase-cis, integration-test-all]
  # sample request
  # PERSONAL_ACCESS_TOKEN=<GITHUB_PERSONAL_ACCESS_TOKEN>
  # REPO_NAME=WASdev/azure.websphere-traditional.image
  # curl --verbose -X POST https://api.github.com/repos/${REPO_NAME}/dispatches -H "Accept: application/vnd.github.everest-preview+json" -H "Authorization: token ${PERSONAL_ACCESS_TOKEN}" --data '{"event_type": "integration-test-twasbase-cis"}'
  # curl --verbose -X POST https://api.github.com/repos/${REPO_NAME}/dispatches -H "Accept: application/vnd.github.everest-preview+json" -H "Authorization: token ${PERSONAL_ACCESS_TOKEN}" --data '{"event_type": "integration-test-all"}'

env:
  repoName: azure.websphere-traditional.image
  userName: ${{ secrets.USER_NAME }}
  azureCredentials: ${{ secrets.AZURE_CREDENTIALS }}
  entitledIbmUserId: ${{ secrets.ENTITLED_IBM_USER_ID }}
  entitledIbmPassword: ${{ secrets.ENTITLED_IBM_USER_PWD }}
  unEntitledIbmUserId: ${{ secrets.UNENTITLED_IBM_USER_ID }}
  unEntitledIbmPassword: ${{ secrets.UNENTITLED_IBM_USER_PWD }}
  msTeamsWebhook: ${{ secrets.MSTEAMS_WEBHOOK }}
  vmAdminId: ${{ secrets.VM_ADMIN_ID }}
  vmAdminPassword: ${{ secrets.VM_ADMIN_PASSWORD }}
  testResourceGroup: twasBaseCISImageTest${{ github.run_id }}${{ github.run_number }}
  vmName: vm${{ github.run_id }}${{ github.run_number }}
  vhdStorageAccountName: storage${{ github.run_id }}${{ github.run_number }}
  containerName: vhds
  osDiskSnapshotName: osdisk-backup
  dataDiskSnapshotName: datadisk-backup
  osDiskVHDName: osdisk.vhd
  dataDiskVHDName: datadisk.vhd
  location: eastus
  scriptLocation: https://raw.githubusercontent.com/${{ secrets.USER_NAME }}/azure.websphere-traditional.image/$GITHUB_REF_NAME/twas-base-cis/test/

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      - name: Get versions of external dependencies
        run: |
          curl -Lo external-deps-versions.properties https://raw.githubusercontent.com/Azure/azure-javaee-iaas/main/external-deps-versions.properties
          source external-deps-versions.properties
          echo "azCliVersion=${AZ_CLI_VERSION}" >> $GITHUB_ENV
          echo "refArmttk=${ARM_TTK_REFERENCE}" >> $GITHUB_ENV
          echo "refJavaee=${AZURE_JAVAEE_IAAS_REFERENCE}" >> $GITHUB_ENV
      - name: Set up JDK 8
        uses: actions/setup-java@v2
        with:
          distribution: 'zulu'
          java-version: '8'
      - name: Checkout azure-javaee-iaas
        uses: actions/checkout@v3
        with:
          repository: Azure/azure-javaee-iaas
          path: azure-javaee-iaas
          ref: ${{ env.refJavaee }}
      - name: Checkout arm-ttk
        uses: actions/checkout@v3
        with:
          repository: Azure/arm-ttk
          path: arm-ttk
          ref: ${{ env.refArmttk }}
      - name: Checkout ${{ env.repoName }}
        uses: actions/checkout@v3
        with:
          path: ${{ env.repoName }}
          ref: ${{ github.event.inputs.ref }}
      - name: Build azure-javaee-iaas
        run: mvn -DskipTests clean install --file azure-javaee-iaas/pom.xml
      - name: Azure login
        uses: azure/login@v1
        with:
          creds: ${{ env.azureCredentials }}
      - name: Build ${{ env.repoName }}
        run: |
          echo "Branch name is $GITHUB_REF_NAME"
          mvn -Dgit.repo=${{ env.userName }} -Dgit.tag=$GITHUB_REF_NAME \
            -DibmUserId=${{ env.entitledIbmUserId }} -DibmUserPwd=${{ env.entitledIbmPassword }} \
            -DstorageAccount=${{ env.vhdStorageAccountName }} -DvmName=${{ env.vmName }} \
            -DvmAdminId=${{ env.vmAdminId }} -DvmAdminPwd=${{ env.vmAdminPassword }} \
            -Dtest.args="-Test All" -Ptemplate-validation-tests -Dtemplate.validation.tests.directory=../../arm-ttk/arm-ttk \
            clean install --file ${{ env.repoName }}/twas-base-cis/pom.xml
      - name: Deploy a CIS compliant RHEL 8.x VM and install twas Base server
        run: |
          cd ${{ env.repoName }}/twas-base-cis/target/cli
          chmod a+x deploy.azcli
          ./deploy.azcli -n testDeployment -g ${{ env.testResourceGroup }} -l ${{ env.location }}
      - name: Query public IP of VM
        uses: azure/CLI@v1
        with:
          azcliversion: ${{ env.azCliVersion }}
          inlineScript: |
            echo "query public ip"
            publicIP=$(az vm show \
              --resource-group ${{ env.testResourceGroup }} \
              --name ${{ env.vmName }} -d \
              --query publicIps -o tsv)
            echo "publicIP=${publicIP}" >> $GITHUB_ENV
      - name: Output installation log
        run: |
          echo "pubilc IP of VM: ${publicIP}"
          echo install sshpass
          sudo apt-get install -y sshpass
          timeout 1m sh -c 'until nc -zv $0 $1; do echo "nc rc: $?"; sleep 5; done' ${publicIP} 22
          echo "Output stdout:"
          result=$(sshpass -p ${{ env.vmAdminPassword }} -v ssh -p 22 -o StrictHostKeyChecking=no -o TCPKeepAlive=yes -o ServerAliveCountMax=20 -o ServerAliveInterval=15 -o ConnectTimeout=100 -v -tt ${{ env.vmAdminId }}@${publicIP} 'echo "${{ env.vmAdminPassword }}" | sudo -S cat /var/lib/waagent/custom-script/download/0/stdout')
          echo "$result"
      - name: Install libXaw
        run: |
          echo "pubilc IP of VM: ${publicIP}"
          echo "yum update starts"
          echo install sshpass
          sudo apt-get install -y sshpass
          timeout 1m sh -c 'until nc -zv $0 $1; do echo "nc rc: $?"; sleep 5; done' ${publicIP} 22
          sshpass -p ${{ env.vmAdminPassword }} -v ssh -p 22 -o StrictHostKeyChecking=no -o TCPKeepAlive=yes -o ServerAliveCountMax=20 -o ServerAliveInterval=15 -o ConnectTimeout=100 -v -tt ${{ env.vmAdminId }}@${publicIP} 'echo "${{ env.vmAdminPassword }}" | sudo  -S yum install libXaw -y'
      - name: Install cifs-utils
        run: |
          echo "pubilc IP of VM: ${publicIP}"
          echo "yum update starts"
          echo install sshpass
          sudo apt-get install -y sshpass
          timeout 1m sh -c 'until nc -zv $0 $1; do echo "nc rc: $?"; sleep 5; done' ${publicIP} 22
          sshpass -p ${{ env.vmAdminPassword }} -v ssh -p 22 -o StrictHostKeyChecking=no -o TCPKeepAlive=yes -o ServerAliveCountMax=20 -o ServerAliveInterval=15 -o ConnectTimeout=100 -v -tt ${{ env.vmAdminId }}@${publicIP} 'echo "${{ env.vmAdminPassword }}" | sudo  -S yum install cifs-utils -y'
      - name: Update applications
        run: |
          echo "pubilc IP of VM: ${publicIP}"
          echo "yum update starts"
          echo install sshpass
          sudo apt-get install -y sshpass
          timeout 1m sh -c 'until nc -zv $0 $1; do echo "nc rc: $?"; sleep 5; done' ${publicIP} 22
          sshpass -p ${{ env.vmAdminPassword }} -v ssh -p 22 -o StrictHostKeyChecking=no -o TCPKeepAlive=yes -o ServerAliveCountMax=20 -o ServerAliveInterval=15 -o ConnectTimeout=100 -v -tt ${{ env.vmAdminId }}@${publicIP} 'echo "${{ env.vmAdminPassword }}" | sudo -S yum update -y'
      - name: Deprovision the VM
        run: |
          echo "pubilc IP of VM: ${publicIP}"
          echo "Deprovision starts"
          echo install sshpass
          sudo apt-get install -y sshpass
          timeout 1m sh -c 'until nc -zv $0 $1; do echo "nc rc: $?"; sleep 5; done' ${publicIP} 22
          sshpass -p ${{ env.vmAdminPassword }} -v ssh -p 22 -o StrictHostKeyChecking=no -o TCPKeepAlive=yes -o ServerAliveCountMax=20 -o ServerAliveInterval=15 -o ConnectTimeout=100 -v -tt ${{ env.vmAdminId }}@${publicIP} 'echo "${{ env.vmAdminPassword }}" | sudo -S waagent -deprovision+user -force'
      - name: Generate the image
        run: |
          az vm deallocate --resource-group ${{ env.testResourceGroup }} --name ${{ env.vmName }}
          az vm generalize --resource-group ${{ env.testResourceGroup }} --name ${{ env.vmName }}
          az image create --resource-group ${{ env.testResourceGroup }} --name ${{ env.vmName }} --source ${{ env.vmName }}
      - name: Verify the image
        run: |
          # Retrieve CIS image info
          regex="^cis\.image\.publisher=(.*)"
          if [[ $(cat ${{ env.repoName }}/config.properties | grep "cis.image.publisher") =~ $regex ]]; then
            cisImagePublisher="${BASH_REMATCH[1]}"
          else
            exit 1
          fi
          regex="^cis\.image\.offer=(.*)"
          if [[ $(cat ${{ env.repoName }}/config.properties | grep "cis.image.offer") =~ $regex ]]; then
            cisImageOffer="${BASH_REMATCH[1]}"
          else
            exit 1
          fi
          regex="^cis\.image\.sku=(.*)"
          if [[ $(cat ${{ env.repoName }}/config.properties | grep "cis.image.sku") =~ $regex ]]; then
            cisImageSku="${BASH_REMATCH[1]}"
          else
            exit 1
          fi
          
          imageResourceId=$(az image show --name ${{ env.vmName }} --resource-group ${{ env.testResourceGroup }} --query id -o tsv)
          
          # Deploy VMs using different IBMids and verify installation
          vmGroups=( ${{ env.testResourceGroup }}-entitled ${{ env.testResourceGroup }}-unentitled ${{ env.testResourceGroup }}-evaluation )
          deploymentModes=( Entitled Unentitled Evaluation )
          ibmUserIds=( ${{ env.entitledIbmUserId }} ${{ env.unEntitledIbmUserId }} "" )
          ibmUserPwds=( ${{ env.entitledIbmPassword }} ${{ env.unEntitledIbmPassword }} "" )
          for (( i=0; i<${#vmGroups[@]}; i++ )); do
            rgName=${vmGroups[$i]}
            az group create -n $rgName -l ${{ env.location }}
            
            az deployment group create --resource-group $rgName --name testDeployment \
              --template-file ${{ env.repoName }}/twas-base-cis/test/mainTemplate.json \
              --parameters deploymentMode=${deploymentModes[$i]} ibmUserId=${ibmUserIds[$i]} ibmUserPwd=${ibmUserPwds[$i]} \
                imageResourceId=$imageResourceId vmAdminId=${{ env.vmAdminId }} vmAdminPwd=${{ env.vmAdminPassword }} \
                cisImagePublisher=$cisImagePublisher cisImageOffer=$cisImageOffer cisImageSku=$cisImageSku \
                scriptLocation=${{ env.scriptLocation }}
            
            az group delete -n $rgName --yes
          done
      - name: Extract VHD files from the VM
        run: |
          # Take snapshots of the VM disks
          osDiskId=$(az vm show \
            -g ${{ env.testResourceGroup }} \
            -n ${{ env.vmName }} \
            --query "storageProfile.osDisk.managedDisk.id" \
            -o tsv)
          az snapshot create \
            -g ${{ env.testResourceGroup }} \
            --source "$osDiskId" \
            --name ${{ env.osDiskSnapshotName }}
          dataDiskId=$(az vm show \
            -g ${{ env.testResourceGroup }} \
            -n ${{ env.vmName }} \
            --query "storageProfile.dataDisks[0].managedDisk.id" \
            -o tsv)
          az snapshot create \
            -g ${{ env.testResourceGroup }} \
            --source "$dataDiskId" \
            --name ${{ env.dataDiskSnapshotName }}
          
          # Generate VHD files
          storageAccountKey=$(az storage account keys list \
            --account-name ${{ env.vhdStorageAccountName }} \
            --query "[?keyName=='key1'].value" -o tsv)
          sasExpiryDuration=3600
          osDiskSnapshotSas=$(az snapshot grant-access \
            --resource-group ${{ env.testResourceGroup }} \
            --name ${{ env.osDiskSnapshotName }} \
            --duration-in-seconds $sasExpiryDuration \
            --query [accessSas] -o tsv)
          az storage blob copy start \
            --destination-blob ${{ env.osDiskVHDName }} \
            --destination-container ${{ env.containerName }} \
            --account-name ${{ env.vhdStorageAccountName }} \
            --account-key $storageAccountKey \
            --source-uri $osDiskSnapshotSas
          dataDiskSnapshotSas=$(az snapshot grant-access \
            --resource-group ${{ env.testResourceGroup }} \
            --name ${{ env.dataDiskSnapshotName }} \
            --duration-in-seconds $sasExpiryDuration \
            --query [accessSas] -o tsv)
          az storage blob copy start \
            --destination-blob ${{ env.dataDiskVHDName }} \
            --destination-container ${{ env.containerName }} \
            --account-name ${{ env.vhdStorageAccountName }} \
            --account-key $storageAccountKey \
            --source-uri $dataDiskSnapshotSas

          # Wait until blob copy of os disk snapshot and data disk snpashot are done
          vhdFiles=( ${{ env.osDiskVHDName }} ${{ env.dataDiskVHDName }} )
          for vhdFile in "${vhdFiles[@]}"; do
            isDone=false
            while [ $isDone = false ]
            do
              result=$(az storage blob show \
                -c ${{ env.containerName }} \
                -n $vhdFile \
                --account-name ${{ env.vhdStorageAccountName }} \
                --account-key $storageAccountKey \
                --query properties.copy.status -o tsv)
              if [[ $result = success ]]; then
                  echo "Blob copy $vhdFile is done."
                  isDone=true
              else
                  echo "Waiting for blob copy $vhdFile completed..."
                  sleep 10
              fi
            done
          done

          # Revoke access for disk snapshots
          az snapshot revoke-access --ids \
            $(az snapshot show -g ${{ env.testResourceGroup }} -n ${{ env.osDiskSnapshotName }} --query id -o tsv) \
            $(az snapshot show -g ${{ env.testResourceGroup }} -n ${{ env.dataDiskSnapshotName }} --query id -o tsv)
      - name: Clean up resources but vhd storage account
        uses: azure/CLI@v1
        with:
          azcliversion: ${{ env.azCliVersion }}
          inlineScript: |
            az image delete --ids \
              $(az image show -g ${{ env.testResourceGroup }} -n ${{ env.vmName }} --query id -o tsv)
            az vm delete --yes --ids \
              $(az vm show -g ${{ env.testResourceGroup }} -n ${{ env.vmName }} --query id -o tsv)
            az network nic delete --ids \
              $(az network nic list -g ${{ env.testResourceGroup }} --query [0].id -o tsv)
            az network vnet delete --ids \
              $(az network vnet list -g ${{ env.testResourceGroup }} --query [0].id -o tsv)
            az network public-ip delete --ids \
              $(az network public-ip list -g ${{ env.testResourceGroup }} --query [0].id -o tsv)
            az network nsg delete --ids \
              $(az network nsg list -g ${{ env.testResourceGroup }} --query [0].id -o tsv)
            az snapshot delete -g ${{ env.testResourceGroup }} -n ${{ env.osDiskSnapshotName }}
            az snapshot delete -g ${{ env.testResourceGroup }} -n ${{ env.dataDiskSnapshotName }}
            az disk delete --yes --ids \
              $(az disk list -g ${{ env.testResourceGroup }} | jq -r 'map(.id) | join(" ")')
      - name: Generate SAS url
        run: |
          # Get a minus-24-hour date and a plus-30-day date for the SAS token
          minus24HoursUtc=$(date -u --date "$dte -24 hour" +%Y-%m-%dT%H:%MZ)
          plus30DaysUtc=$(date -u --date "$dte 30 day" +%Y-%m-%dT%H:%MZ)

          vhdStorageAccountAccessKey=$(az storage account keys list --account-name ${{ env.vhdStorageAccountName }} --query "[?keyName=='key1'].value" -o tsv)
          sasToken=$(az storage container generate-sas \
            --connection-string "DefaultEndpointsProtocol=https;AccountName=${{ env.vhdStorageAccountName }};AccountKey=${vhdStorageAccountAccessKey};EndpointSuffix=core.windows.net" \
            --name ${{ env.containerName }} --permissions rl --start "${minus24HoursUtc}" --expiry "${plus30DaysUtc}" -o tsv)
          blobStorageEndpoint=$( az storage account show -n ${{ env.vhdStorageAccountName }} -g ${{ env.testResourceGroup }} -o json | jq -r '.primaryEndpoints.blob' )
          osDiskSasUrl=${blobStorageEndpoint}${{ env.containerName }}/${{ env.osDiskVHDName }}?$sasToken
          dataDiskSasUrl=${blobStorageEndpoint}${{ env.containerName }}/${{ env.dataDiskVHDName }}?$sasToken
          
          echo "osDiskSasUrl: ${osDiskSasUrl}, dataDiskSasUrl: ${dataDiskSasUrl}" > sas-url.txt
      - name: Upload sas-url.txt
        uses: actions/upload-artifact@v3
        with:
          name: sasurl
          path: sas-url.txt
  summary:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Download sas-url.txt
        uses: actions/download-artifact@v3
        with:
          name: sasurl
